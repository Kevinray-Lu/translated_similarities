{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcec41fd-c712-403c-94c9-dc8933199758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId\n",
    "#used mongo to access online storage, fill in brackets in mongoclient() to connect to your own db\n",
    "conn = MongoClient()\n",
    "db = conn.study  #连接mydb数据库，没有则自动创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74f5fbc-4b31-4c7a-b1d0-684b31dfb7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import synonyms\n",
    "import re\n",
    "# import Cilin similarity for testing.\n",
    "from cilin import CilinSimilarity\n",
    "\n",
    "# initialize stop words dictionary, this includes common meaningless words after translation from English to Chinese\n",
    "except_words = ['的', '，', '地', '…','...', '或', '；', '为', '上', '(', ')', ' ', '大量'\n",
    "        , '使', '发生', '在', '有', '把', '不', 'adv', '等', 'adj', '.' ,'（', 'vi','vt', 'phr','某人','']\n",
    "def comparemax(word1, word2):\n",
    "    cs = CilinSimilarity()\n",
    "    # clean out extra spaces around word translations\n",
    "    word1 = word1.strip()\n",
    "    word2 = word2.strip()\n",
    "    clean_word1 = ''.join(re.findall(r'[\\u4e00-\\u9fa5]', word1))\n",
    "    # tokenize words for sub-component similarity comparisons\n",
    "    final_word1 = list(jieba.lcut(clean_word1))\n",
    "    #print(final_word1)\n",
    "    clean_word2 = ''.join(re.findall(r'[\\u4e00-\\u9fa5]', word2))\n",
    "    final_word2 = list(jieba.lcut(clean_word2))\n",
    "\n",
    "    #print(final_word2)\n",
    "    similarity = 0\n",
    "    # compare similarities according to sub-components\n",
    "    for word in final_word1:\n",
    "        #skip stop words\n",
    "        if word in except_words:# or len(word) == 1:\n",
    "            continue\n",
    "        word_sim = 0\n",
    "        for word2 in final_word2:\n",
    "            if word2 in except_words:# or len(word) == 1:\n",
    "                continue\n",
    "            if word == word2:\n",
    "                word_sim = 1\n",
    "            sim = cs.similarity(word, word2)\n",
    "#            if sim > 0.8 and sim < 1:\n",
    "#             print(word, word2, sim)\n",
    "            #choose max score as the similarity score\n",
    "            word_sim = max(sim, word_sim)\n",
    "        similarity = max(word_sim, similarity)\n",
    "    pair = [clean_word2, similarity]\n",
    "    print(similarity)\n",
    "    if similarity >= 0.8:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "print(comparemax(\"不行\",\"不好\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b555096-d999-4a68-af9c-d13b9964499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a different approach involving weighted score when comparing similarities\n",
    "import jieba\n",
    "import synonyms\n",
    "import re\n",
    "from cilin import CilinSimilarity\n",
    "\n",
    "except_words = ['的', '，', '地', '…','...', '或', '；', '为', '上', '(', ')', ' ', '大量'\n",
    "        , '使', '发生', '在', '有', '把', '不', 'adv', '等', 'adj', '.' ,'（', 'vi','vt', 'phr','某人','']\n",
    "\n",
    "def compare(word1, word2):\n",
    "    cs = CilinSimilarity()\n",
    "    word1 = word1.strip()\n",
    "    word2 = word2.strip()\n",
    "    clean_word1 = ''.join(re.findall(r'[\\u4e00-\\u9fa5]', word1))\n",
    "    final_word1 = list(jieba.lcut(clean_word1))\n",
    "    clean_word2 = ''.join(re.findall(r'[\\u4e00-\\u9fa5]', word2))\n",
    "    final_word2 = list(jieba.lcut(clean_word2))\n",
    "\n",
    "    index = 0\n",
    "    for i in range(len(final_word1)):\n",
    "        if (final_word1[index] in except_words):\n",
    "            final_word1.remove(final_word1[index])\n",
    "        else:\n",
    "            index += 1\n",
    "    index2 = 0\n",
    "    for j in range(len(final_word2)):\n",
    "        if (final_word2[index2] in except_words):\n",
    "            final_word2.remove(final_word2[index2])\n",
    "        else:\n",
    "            index2 += 1\n",
    "            \n",
    "    similarity = 0\n",
    "\n",
    "    for word in final_word1:\n",
    "        word_sim = 0\n",
    "        for word2 in final_word2:\n",
    "            # apply double weights to sub-components with similarity score = 1\n",
    "            if cs.similarity(word, word2) == 1 or word == word2:\n",
    "                word_sim += 2\n",
    "            word_sim += cs.similarity(word, word2)\n",
    "        similarity += word_sim\n",
    "    # weight the total score\n",
    "    similarity /= (len(final_word1)*len(final_word2))\n",
    "    pair = [clean_word2, similarity]\n",
    "    if similarity >= 0.8:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f777fec8-5711-471c-9592-8f7cdd940aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example using self-created dictionary\n",
    "words = db.words.find({\n",
    "})\n",
    "\n",
    "# every word should have its chinese translations and option candidates for multiple choice questions, our task is to eliminate options that are too similar to the correct answer.\n",
    "for word in words:\n",
    "        #optionRows = db.word_options.find({'word_id': str(word['_id'])})\n",
    "        optionWords = db.words.find({'_id': {'$in': [x['option_id'] for x in optionRows] }})\n",
    "        options = []\n",
    "\n",
    "        for optionWord in optionWords:\n",
    "            for de in optionWord['definitions']:\n",
    "                options.append({'chinese':de['chinese'], 'option_id': optionWord['_id'], 'word': optionWord['word']})\n",
    "        # compare every correct translation and option translations\n",
    "        for definition in word['definitions']:\n",
    "            for option in options:\n",
    "                if compare(definition['chinese'], option['chinese']):\n",
    "                    print('原词: ', word['number'], word['word'], definition['chinese'],' ==== ',option['word'], option['chinese'])\n",
    "    #                 db.word_options.delete_one({'word_id': str(word['_id']), 'option_id': option['option_id']})\n",
    "'''        # 比较干扰项之间\n",
    "        for option1 in options:\n",
    "            for option2 in options:\n",
    "                if compare(option1['chinese'], option2['chinese']) and option1 != option2:\n",
    "                    print('干扰项：', word['number'], word['word'],option1['word'], option1['chinese'],' = [干扰项] ',option2['word'],\n",
    "                          option2['chinese'],option2['option_id'])\n",
    "    #                 db.word_options.delete_one({'word_id': str(word['_id']), 'option_id': option2['option_id']})\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6172381e-7b7b-452e-9958-a69b46228808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are still at least 8 options available after filtering. We would like to randomly select 4 of them for multiple choice questions\n",
    "words = db.words.find({\n",
    "    \"wordbook_id\": ObjectId('5eb9336b9f84b8d354223b8b'),\n",
    "})\n",
    "for word in words:\n",
    "    option_count = db.word_options.find({'word_id': str(word['_id'])}).count()\n",
    "    if option_count <8:\n",
    "        print(word['number'],word['word'],option_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
